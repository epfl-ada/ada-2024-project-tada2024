ASCII ( A merican S tandard C ode for I nformation I nterchange ), generally pronounced [ˈæski] , is a character encoding based on the English alphabet. ASCII codes represent text in computers , communications equipment, and other devices that work with text. Most modern character encodings—which support many more characters—have a historical basis in ASCII.
ASCII was first published as a standard in 1967 and was last updated in 1986. It currently defines codes for 128 characters. 33 are non-printing, mostly obsolete control characters that affect how text is processed, and the other 95 printable characters are as follows (starting with the space character):
 !"#$%&'()*+,-./0123456789:;<=>?
@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_
`abcdefghijklmnopqrstuvwxyz{|}~
## Overview
Like other character representation computer codes, ASCII specifies a correspondence between digital bit patterns and the symbols/ glyphs of a written language, thus allowing digital devices to communicate with each other and to process, store, and communicate character-oriented information. The ASCII character encoding — or a compatible extension (see below) — is used on nearly all common computers, especially personal computers and workstations. The preferred MIME name for this encoding is "US-ASCII".
ASCII is, strictly, a seven- bit code, meaning that it uses the bit patterns representable with seven binary digits (a range of 0 to 127 decimal) to represent character information. At the time ASCII was introduced, many computers dealt with eight-bit groups ( bytes or, more specifically, octets) as the smallest unit of information; the eighth bit was commonly used as a parity bit for error checking on communication lines or other device-specific functions. Machines which did not use parity typically set the eighth bit to zero, though some systems such as Prime machines running PRIMOS set the eighth bit of ASCII characters to one.
ASCII only defines a relationship between specific characters and bit sequences; aside from reserving a few control codes for line-oriented formatting, it does not define any mechanism for describing the structure or appearance of text within a document. Such concepts are within the realm of other systems such as the markup languages .
### History
ASCII developed from telegraphic codes and first entered commercial use as a seven-bit teleprinter code promoted by Bell data services in 1963. The Bell System had previously planned to use a six-bit code, derived from Fieldata, that added punctuation and lower-case letters to the earlier five-bit Baudot teleprinter code, but was persuaded instead to join the ASA subcommittee that had started to develop ASCII. Baudot helped in the automation of sending and receiving telegraphic messages, and took many features from Morse code; however, unlike Morse code, Baudot used constant-length codes. Compared to earlier telegraph codes, the proposed Bell code and ASCII both underwent re-ordering for more convenient sorting (especially alphabetization) of lists, and added features for devices other than teleprinters. Bob Bemer introduced features such as the ' escape sequence'. His British colleague Hugh McGregor Ross helped to popularize this work, as Bemer said, "so much so that the code that was to become ASCII was first called the Bemer-Ross Code in Europe".
The American Standards Association (ASA, later to become ANSI) first published ASCII as a standard in 1963. ASCII-1963 lacked the lowercase letters, and had an up-arrow (↑) instead of the caret (^) and a left-arrow (←) instead of the underscore (_). The 1967 version added the lowercase letters, changed the names of a few control characters and moved the two controls ACK and ESC from the lowercase letters area into the control codes area.
ASCII was subsequently updated and published as ANSI X3.4-1968, ANSI X3.4-1977, and finally, ANSI X3.4-1986.
Other international standards bodies have ratified character encodings that are identical or nearly identical to ASCII. These encodings are sometimes referred to as ASCII, even though ASCII is strictly defined only by the ASA/ANSI standards:
The European Computer Manufacturers Association published editions of its ASCII clone, ECMA-6, in 1965, 1967, 1970, 1973, 1983, and 1991. The 1991 edition is the same as ANSI X3.4-1986.
The International Organization for Standardization published its version, ISO 646 (later ISO/IEC 646) in 1967, 1972, 1983, and 1991. ISO 646:1972, in particular, established a set of country-specific versions with punctuation characters replaced with non-English letters. ISO/IEC 646:1991 International Reference Version is the same as ANSI X3.4-1986.
The International Telecommunication Union published its version of ANSI X3.4-1986, ITU-T Recommendation T.50, in 1992. In the early 1970s, under the name CCITT, the same organization published a version as CCITT Recommendation V.3.
DIN published a version of ASCII as DIN 66003 in 1974.
The IETF published a version in 1969 as RFC 20, and established the Internet's standard version, based on ANSI X3.4-1986, with the publication of RFC 1345 in 1992.
IBM's version of ANSI X3.4-1986 is published in IBM technical literature as Code page 367.
ASCII has also become embedded in its probable replacement, Unicode, as the 'lowest' 128 characters. In terms of mere adoption, ASCII is one of the most successful software standards ever.
## ASCII control characters
ASCII reserves the first 32 codes (numbers 0–31 decimal) for control characters: codes originally intended not to carry printable information, but rather to control devices (such as printers) that make use of ASCII, or to provide meta-information about data streams such as those stored on magnetic tape. For example, character 10 represents the "line feed" function (which causes a printer to advance its paper), and character 8 represents "backspace".
Printable Representation, the Unicode characters reserved for representing control characters when it is necessary to print or display them rather than have them perform their intended function. Some browsers may not display these properly.
Control key Sequence, the traditional key sequences for inputting control characters. The caret (^) represents the "Control" or "Ctrl" key that must be held down while pressing the second key in the sequence. The caret-key representation is also used by some software to represent control characters.
Character Escape Codes in C programming language and many other languages influenced by it, such as Java and Perl .
The Backspace character can also be entered by pressing the "Backspace", "Bksp", or ← key on some systems.
The Delete character can also be entered by pressing the "Delete" or "Del" key. It can also be entered by pressing the "Backspace", "Bksp", or ← key on some systems.
The Escape character can also be entered by pressing the "Escape" or "Esc" key on some systems.
The Carriage Return character can also be entered by pressing the "Return", "Ret", "Enter", or ↵ key on most systems.
The ambiguity surrounding Backspace comes from mismatches between the intent of the human or software transmitting the Backspace and the interpretation by the software receiving it. If the transmitter expects Backspace to erase the previous character and the receiver expects Delete to be used to erase the previous character, many receivers will echo the Backspace as "^H", just as they would echo any other uninterpreted control character. (A similar mismatch in the other direction may yield Delete displayed as "^?".) "^H" persists in messages today as a deliberate humorous device — for example, "there's a sucker^H^H^H^H^H^Hpotential customer born every minute". A less common variant of this involves the use of "^W", which in some user interfaces means "delete previous word". The example sentence would therefore also work as "there's a sucker^W potential customer born every minute".
The original ASCII standard used only short descriptive phrases for each control character. The ambiguity this left was sometimes intentional (where a character would be used slightly differently on a terminal link than on a data stream) and sometimes more accidental (such as what "delete" means).
Probably the most influential single device on the interpretation of these characters was the Teletype corporation model 33 series, which was a printing terminal with an available paper tape reader/punch option. Paper tape was a very popular medium for long-term program storage up through the 1980s, lower cost and in some ways less fragile than magnetic tape. In particular, the Teletype 33 machine assignments for codes 17 (Control-Q, DC1, also known as XON), 19 (Control-S, DC3, also known as XOFF), and 127 (DELete) became de-facto standards. Its noncompliant use of code 15 (Control-O, Shift In) as "left arrow", usually interpreted as "delete previous character" was also adopted by many early timesharing systems but eventually faded out.
The use of Control-S (XOFF, an abbreviation for "transmit off") as a handshaking signal warning a sender to stop transmission because of impending overflow, and Control-Q (XON, "transmit on") to resume sending, persists to this day in many systems as a manual output control technique. On some systems Control-S retains its meaning but Control-Q is replaced by a second Control-S to resume output.
Code 127 is officially named "delete" but the Teletype label was "rubout". Since the original standard gave no detailed interpretation for most control codes, interpretations of this code varied. The original Teletype meaning was to make it an ignored character, the same as NUL (all zeroes). This was specifically useful for paper tape, because punching the all-ones bit pattern on top of an existing mark would obliterate it. Tapes designed to be "hand edited" could even be produced with spaces of extra NULs (blank tape) so that a block of characters could be "rubbed out" and then replacements put into the empty space.
As video terminals began to replace printing ones, the value of the "rubout" character was lost. Unix systems, for example, interpreted "Delete" to mean "remove the character before the cursor". Most other systems used "Backspace" for that meaning and used "Delete" to mean "remove the character after the cursor". That latter interpretation is the most common today.
Many more of the control codes have taken on meanings quite different from their original ones. The "escape" character (code 27), for example, was originally intended to allow sending other control characters as literals instead of invoking their meaning. This is the same meaning of "escape" encountered in URL encodings, C language strings, and other systems where certain characters have a reserved meaning. Over time this meaning has been coopted and has eventually drifted. In modern use, an ESC sent to the terminal usually indicates the start of a command sequence, usually in the form of an ANSI escape code. An ESC sent from the terminal is most often used as an "out of band" character used to terminate an operation, as in the TECO and vi text editors.
The inherent ambiguity of many control characters, combined with their historical usage, has also created problems when transferring "plain text" files between systems. The clearest example of this is the newline problem on various operating systems. On printing terminals there is no question that you terminate a line of text with both "Carriage Return" and "Linefeed". The first returns the printing carriage to the beginning of the line and the second advances to the next line without moving the carriage. However, requiring two characters to mark the end of a line introduced unnecessary complexity and questions as to how to interpret each character when encountered alone. To simplify matters, plain text files on Unix systems use line feeds alone to separate lines. Similarly, older Macintosh systems, among others, use only carriage returns in plain text files. Various DEC operating systems used both characters to mark the end of a line, perhaps for compatibility with teletypes, and this de facto standard was copied in the CP/M operating system and then in MS-DOS and eventually Microsoft Windows . The DEC operating systems, along with CP/M, tracked file length only in units of disk blocks and used Control-Z (SUB) to mark the end of the actual text in the file (also done for CP/M compatibility in some cases in MS-DOS, though MS-DOS has always recorded exact file-lengths). Control-C (ETX, End of TeXt) might have made more sense, but was already in wide use as a program abort signal. UNIX's use of Control-D (EOT, End of Transmission) appears on its face similar, but is used only from the terminal and never stored in a file.
While the codes mentioned above have retained some semblance of their original meanings, many of the codes originally intended for stream delimiters or for link control on a terminal have lost all meaning except their relation to a letter. Control-A is almost never used to mean "start of header" except on an ANSI magnetic tape. When connecting a terminal to a system, or asking the system to recognize that a logged-out terminal wants to log in, modern systems are much more likely to want a carriage return or an ESCape than Control-E (ENQuire, meaning "is there anybody out there?").
## ASCII printable characters
Code 32, the "space" character, denotes the space between words, as produced by the large space-bar of a keyboard. Codes 33 to 126, known as the printable characters, represent letters, digits, punctuation marks, and a few miscellaneous symbols.
Seven-bit ASCII provided seven "national" characters and, if the combined hardware and software permit, can use overstrikes to simulate some additional international characters: in such a scenario a backspace can precede a grave accent (which the American and British standards, but only those standards, also call "opening single quotation mark"), a backtick, or a breath mark (inverted vel).
## Structural features
The digits 0-9 are represented with their values in binary prefixed with 0011 (this means that converting BCD to ASCII is simply a matter of taking each BCD nibble separately and prefixing 0011 to it).
Lowercase and uppercase letters only differ in bit pattern by a single bit simplifying case conversion to a range test (to avoid converting characters that are not letters) and a single bitwise operation. Fast case conversion is important because it is often used in case-ignoring search algorithms.
## Aliases for ASCII
RFC 1345 (published in June 1992) and the IANA registry of character sets (ongoing), both recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:
ANSI_X3.4-1968 (canonical name)
ANSI_X3.4-1986
ASCII (with ASCII-7 and ASCII-8 variants)
US-ASCII (preferred MIME name)
us
ISO646-US
ISO_646.irv:1991
iso-ir-6
IBM367
cp367
csASCII
Of these, only the aliases "US-ASCII" and "ASCII" have achieved widespread use. One often finds them in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prolog of some XML documents.
## Variants of ASCII
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII in order to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some mis-apply that term to cover all variants, including those that do not preserve ASCII's character-map in the 7-bit range.
The PETSCII Code used by Commodore International for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963 instead of the far more common ASCII-1967.
### Incompatability vs Interoperability
ISO 646 (1972), the first attempt to remedy the pro-English-language bias, created compatibility problems, since it remained a 7-bit character-set. It made no additional codes available, so it reassigned some in language-specific variants. It thus became impossible to know what character a code represented without knowing which variant to work with, and text-processing systems could generally cope with only one variant anyway.
Eventually, improved technology brought out-of-band means to represent the information formerly encoded in the eighth bit of each byte, freeing this bit to add another 128 additional character-codes for new assignments.
For example, IBM developed 8-bit code pages, such as code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal.
Eight-bit standards such as ISO/IEC 8859 (derived from the DEC-MCS) and Mac OS Roman developed as true extensions of ASCII, leaving the original character-mapping intact and just adding additional values above the 7-bit range.
This enabled the representation of a broader range of languages, but these standards continued to suffer from incompatibilities and limitations. Still, ISO-8859-1, its variant Windows-1252 (often mislabeled as ISO-8859-1 even by Microsoft software) and original 7-bit ASCII remain the most common character encodings in use today.
### The Unicode fix
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII basically uses 7-bit codes, Unicode and the UCS use relatively abstract "code points": non-negative integer numbers that map, using different encoding forms and schemes, to sequences of one or more 8-bit bytes. To permit backward compatibility, Unicode and the UCS assign the first 128 code points to the same characters as ASCII. One can therefore think of ASCII as a 7-bit encoding scheme for a very small subset of Unicode and of the UCS.
The popular UTF-8 (and UTF-7) encoding-form prescribes the use of one to four 8-bit code values for each code point character, and equates exactly to ASCII for the code values below 128. Other encoding forms such as UTF-16 resemble ASCII in how they represent the first 128 characters of Unicode, but tend to use 16 or 32 bits per character, so they require conversion for compatibility.
The blend word ASCIIbetical has evolved to describe the collation of data in ASCII-code order rather than "standard" alphabetical order.
The abbreviation ASCIIZ or ASCIZ refers to a null-terminated ASCII string.
## Trivia
Asteroid 3568 ASCII is named after the character encoding.