{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./src/semantic\")\n",
    "\n",
    "import colorsys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# our scripts\n",
    "from src.semantic.perform_clustering import run_all_clustering, run_kimchi_cos\n",
    "from src.semantic.utils.evaluate_clustering import (\n",
    "    calculate_clustering_consistency, get_primary_category,\n",
    "    map_clustering_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Semantic Distances for articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define file paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the category data file\n",
    "category_file = './/data//wikispeedia//wikispeedia_paths-and-graph//categories.tsv'\n",
    "\n",
    "# All paths to the embedding data files\n",
    "MiniLM_file = './/data//semantic//output//embeddings//all_MiniLM_L6_v2.pkl' \n",
    "mpnet_file = './/data//semantic//output//embeddings//all_mpnet_base_v2.pkl' \n",
    "roberta_file = './/data//semantic//output//embeddings//roberta.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Perform Clustering on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For embeddings generated from MiniLM\n",
    "print('------Starting clustering for embeddings based on MiniLM_L6_v2...')\n",
    "MiniLM_clustering = run_all_clustering(MiniLM_file, category_file)\n",
    "print(f\"Perform {list(MiniLM_clustering.keys())} successfully!\")\n",
    "\n",
    "# For embeddings generated from mpnet_base_v2\n",
    "print('------Starting clustering for embeddings based on mpnet_base_v2...')\n",
    "mpnet_clustering = run_all_clustering(mpnet_file, category_file)\n",
    "print(f\"Perform {list(mpnet_clustering.keys())} successfully!\")\n",
    "\n",
    "# Cluster embeddings generated from roberta\n",
    "print('------Starting clustering for embeddings based on roberta...')\n",
    "roberta_clustering = run_all_clustering(roberta_file, category_file)\n",
    "print(f\"Perform {list(roberta_clustering.keys())} successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data structure of the clustering results is as follows:\n",
    "\n",
    "- **MiniLM_clustering**\n",
    "  - **K-Means**: Embeddings (DataFrame)\n",
    "  - **K-Medoids Manhattan**: Embeddings (DataFrame)\n",
    "  - **K-Medoids Cosine**: Embeddings (DataFrame)\n",
    "  - **Spectral Clustering NN**: Embeddings (DataFrame)\n",
    "  - **Spectral Clustering RBF**: Embeddings (DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample of clustering results\n",
    "MiniLM_clustering['K-Means'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Evaluate the clustering results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Clustering Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clustering results from each DataFrame's 'clustering' column and store in a list\n",
    "MiniLM_list = [df['clustering'].tolist() for df in MiniLM_clustering.values()]\n",
    "mpnet_list = [df['clustering'].tolist() for df in mpnet_clustering.values()]\n",
    "roberta_list = [df['clustering'].tolist() for df in roberta_clustering.values()]\n",
    "\n",
    "# Calculate average clustering consistency for each embedding\n",
    "MiniLM_ari, MiniLM_nmi = calculate_clustering_consistency(MiniLM_list)\n",
    "mpnet_ari, mpnet_nmi = calculate_clustering_consistency(mpnet_list)\n",
    "roberta_ari, MiniLM_nmi = calculate_clustering_consistency(roberta_list)\n",
    "\n",
    "# Show the result \n",
    "clustering_consistency = pd.DataFrame({\n",
    "    'Average ARI': [MiniLM_ari, mpnet_ari, roberta_ari],\n",
    "    'Average NMI': [MiniLM_nmi, mpnet_nmi, MiniLM_nmi]\n",
    "})\n",
    "clustering_consistency.index = ['MiniLM', 'mpnet', 'roberta']\n",
    "\n",
    "clustering_consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ARI** and **NMI** are two methods used to evaluate consistency across different clustering results.\n",
    "- **Adjusted Rand Index (ARI):** ARI measures the similarity between two clustering results by considering pairs of points and evaluating how consistently they are grouped across different clusters. (Range: [-1, 1])\n",
    "- **Normalized Mutual Information (NMI):** NMI evaluates the amount of shared information between two clustering results, assessing how well one clustering result predicts the other. (Range: [0, 1])\n",
    "- **Embeddings generated by mpnet** shows the highest scores for both Average ARI (0.147835) and Average NMI (0.317228), indicating the best consistency and stability among the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Category-Cluster Mapping and Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get primary categories for concepts and show the head\n",
    "primary_category = get_primary_category(category_file)\n",
    "primary_category.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dicts to save the mapping results\n",
    "MiniLM_evaluation = {}\n",
    "mpnet_evaluation = {}\n",
    "roberta_evaluation = {}\n",
    "\n",
    "# evaluation on MiniLM_L6_v2\n",
    "print(\"------Clustering accuracy for MiniLM_L6_v2 embeddings:\")\n",
    "for key, value in MiniLM_clustering.items():\n",
    "    cluster_category_mapping, accuracy = map_clustering_category(primary_category, value)\n",
    "    MiniLM_evaluation['key'] = cluster_category_mapping\n",
    "    print(f\"{key}: {accuracy:.2f}\")\n",
    "\n",
    "# evaluation on mpnet_base_v2\n",
    "print(\"------Clustering accuracy for mpnet_base_v2 embeddings:\")\n",
    "for key, value in mpnet_clustering.items():\n",
    "    cluster_category_mapping, accuracy = map_clustering_category(primary_category, value)\n",
    "    mpnet_evaluation['key'] = cluster_category_mapping\n",
    "    print(f\"{key}: {accuracy:.2f}\")\n",
    "\n",
    "# evaluation on mpnet_base_v2\n",
    "print(\"------Clustering accuracy for roberta embeddings:\")\n",
    "for key, value in roberta_clustering.items():\n",
    "    cluster_category_mapping, accuracy = map_clustering_category(primary_category, value)\n",
    "    roberta_evaluation['key'] = cluster_category_mapping\n",
    "    print(f\"{key}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Among all embedding models, mpnet shows the highest degree of alignment with the original primary categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation of different embedings by comparing a clustering to the primary categories \n",
    "\n",
    "## Method\n",
    "We use kmedoids with the **cosine distance** to cluster the embeddings.\n",
    "We set the number of clusters to be equal to the number of primary categories.\n",
    "\n",
    "## Motivations\n",
    "We use cosine distance because it normalises vectors and by doing so, we make sure that the size of the article doesn't act as a confounding factor.\n",
    "We use kmedoids to extract meaning for each cluster by looking at the name and primary category of the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = pd.read_csv(category_file, sep='\\t', skiprows=12, header=None)\n",
    "category_df.columns = ['concept','category']\n",
    "category_df['primary_category'] = category_df['category'].apply(lambda x: x.split('.')[1])\n",
    "category_dict = dict(zip(category_df['concept'], category_df['primary_category']))\n",
    "\n",
    "models = ['all_MiniLM_L6_v2', 'all_mpnet_base_v2', 'roberta']\n",
    "\n",
    "model_clustering_dfs = []\n",
    "for model_name in models:\n",
    "    model_file = f'.//data//semantic//output//embeddings//{model_name}.pkl'\n",
    "    model_cluster = run_kimchi_cos(model_file, category_file)\n",
    "    model_cluster['center_category'] = model_cluster['center_name'].map(category_dict)\n",
    "    model_cluster['members_categories'] = model_cluster['member_names'].apply(\n",
    "        lambda members: [category_dict.get(member, 'Unknown') for member in members]\n",
    "    )\n",
    "    model_clustering_dfs.append(model_cluster)\n",
    "\n",
    "\n",
    "for i, clustering_df in enumerate(model_clustering_dfs): \n",
    "    print(models[i])\n",
    "    print(clustering_df[['center_name', 'center_category', 'cluster_size']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations \n",
    "Most of the cluster centers are related to Science. This is not very surprinsing because, science is the biggest primary category : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df, column, title=None, figsize=(12, 8), top_n=None, sort_by='value'):\n",
    "    \"\"\"\n",
    "    Plot the distribution of values in a specified column of a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - column: str, the name of the column to plot\n",
    "    - title: str, optional, the title of the plot\n",
    "    - figsize: tuple, optional, the size of the figure (width, height)\n",
    "    - top_n: int, optional, limit to top N categories (by frequency or alphabetically)\n",
    "    - sort_by: str, optional, 'value' to sort by frequency (default) or 'index' to sort alphabetically\n",
    "    \"\"\"\n",
    "    value_counts = df[column].value_counts()\n",
    "    if sort_by == 'index':\n",
    "        value_counts = value_counts.sort_index()\n",
    "    if top_n is not None:\n",
    "        value_counts = value_counts.nlargest(top_n) if sort_by == 'value' else value_counts.head(top_n)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    bars = plt.barh(value_counts.index, value_counts.values)\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width, bar.get_y() + bar.get_height()/2, f'{width}', \n",
    "                 ha='left', va='center', fontweight='bold')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel(column)\n",
    "    plt.title(title or f'Distribution of {column}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_distribution(category_df, 'primary_category', title='Distribution of Primary Categories')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_stacked(df, column, members_column, title=None, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Plot the distribution of values with each cluster having a unique color,\n",
    "    sorted by total count and using center_name for cluster labels.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with clustering results\n",
    "    - column: str, column containing center categories\n",
    "    - members_column: str, column containing lists of member categories\n",
    "    - title: str, optional title for the plot\n",
    "    - figsize: tuple, size of the figure\n",
    "    \"\"\"\n",
    "    # Flatten member categories and count occurrences\n",
    "    all_categories = df[members_column].explode().value_counts().index\n",
    "    \n",
    "    # Generate a color palette with a distinct color for each cluster\n",
    "    def generate_distinct_colors(n):\n",
    "        HSV_tuples = [(x*1.0/n, 0.5, 0.5) for x in range(n)]\n",
    "        return list(map(lambda x: colorsys.hsv_to_rgb(*x), HSV_tuples))\n",
    "    \n",
    "    colors = generate_distinct_colors(len(df))\n",
    "    \n",
    "    # Prepare the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Track the bottom of each bar for stacking\n",
    "    bottom = np.zeros(len(all_categories))\n",
    "    \n",
    "    # Plot each cluster with a different color\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        center_name = row['center_name']\n",
    "        member_categories = row[members_column]\n",
    "        \n",
    "        # Count category occurrences for this cluster\n",
    "        category_counts = pd.Series(member_categories).value_counts()\n",
    "        \n",
    "        # Create a bar for each category in this cluster\n",
    "        cluster_bars = []\n",
    "        for cat in all_categories:\n",
    "            count = category_counts.get(cat, 0)\n",
    "            bar = plt.barh(cat, count, left=bottom[all_categories.get_loc(cat)], \n",
    "                           color=colors[i], label=center_name)\n",
    "            cluster_bars.append(bar)\n",
    "            bottom[all_categories.get_loc(cat)] += count\n",
    "    \n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Category')\n",
    "    plt.title(title or 'Distribution of Categories Across Clusters')\n",
    "    \n",
    "    # Add count labels\n",
    "    for cat_idx, cat in enumerate(all_categories):\n",
    "        plt.text(bottom[cat_idx], cat_idx, f'{bottom[cat_idx]:.0f}', \n",
    "                 va='center', ha='left')\n",
    "    \n",
    "    # Customize legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), title='Clusters (Center Names)', \n",
    "               bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "for i, model_cluster in enumerate(model_clustering_dfs):\n",
    "    plot_distribution_stacked(model_cluster, 'center_category', 'members_categories', \n",
    "                      title=f'Distribution of Categories for {models[i]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations : \n",
    "We can see that clusters do not match primary categories at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
